{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise you are going to work on the Yelp database (that can be found here). The goal is to  predict if a comment  about a venue is bad or good. The database contains information such as venue ID, date of comment, rating and of course comments of the users. In order to use the information contained in the comments, you are gonna have to apply some preprocessing to the data.\n",
    "\n",
    "A \"bad\" venue is defined as a venue with a star rating of less or equal to two stars, the other venues being considered as \"good\". Note that this is for the sake of working with a classification problem. One could actually work with the number of stars and use regression algorithms (which could actually be a better idea)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you give as input variable the raw comments of the dataset, you model will be of extremely poor accuracy. Some transformations should be made on the comments to extract the necessary information and put it in a form appropriate for a machine learning model. \n",
    "\n",
    "You should first clean the raw text. The type of cleaning depends on which data you have and what you want to achieve : remove punctation, switch everything to lower case, remove words containing numbers, remove words not adding any information (like \"the\" or \"of\", usually called \"stopwords\"), taking only the root of the words (and therefore consider words with same root but different ending as similar),...  For example, you may want \"*I was disappointed, what a terrible quality of food!!!*\" to be tranformed into \"*disappointed terrible quality food*\".\n",
    "You can have a look at the most frequent words in every classes to have an idea of the quality of your cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Me: Rajat, Email: rjtkpanda@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaded the Modules required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module list is keep getting bigger as we move forward in the process of writing the code\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib                                  #for plotting \n",
    "import matplotlib.pylab as plt                     #for plotting \n",
    "matplotlib.rcParams['savefig.dpi'] = 144\n",
    "matplotlib.rcParams['figure.figsize'] = (10,7)\n",
    "matplotlib.rcParams['xtick.labelsize'] = 15\n",
    "matplotlib.rcParams['ytick.labelsize'] = 15\n",
    "matplotlib.rcParams['lines.markersize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import pipeline\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection and Data exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  f = /home/rajat/git/P2.11/Data/yelp_train_academic_dataset_review.json\n",
    "#Convert a JSON string to pandas object\n",
    "data = pd.read_json('/home/rajat/git/P2.11/Data/yelp_train_academic_dataset_review.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    business_id       date               review_id  stars  \\\n",
      "0        vcNAWiLM4dR7D2nwwJ7nCA 2007-05-17  15SdjuK7DmYqUAj6rjGowg      5   \n",
      "1        vcNAWiLM4dR7D2nwwJ7nCA 2010-03-22  RF6UnRTtG7tWMcrO2GEoAg      2   \n",
      "2        vcNAWiLM4dR7D2nwwJ7nCA 2012-02-14  -TsVN230RCkLYKBeLsuz7A      4   \n",
      "3        vcNAWiLM4dR7D2nwwJ7nCA 2012-03-02  dNocEAyUucjT371NNND41Q      4   \n",
      "4        vcNAWiLM4dR7D2nwwJ7nCA 2012-05-15  ebcN2aqmNUuYNoyvQErgnA      4   \n",
      "5        vcNAWiLM4dR7D2nwwJ7nCA 2013-04-19  _ePLBPrkrf4bhyiKWEn4Qg      1   \n",
      "6        vcNAWiLM4dR7D2nwwJ7nCA 2014-01-02  kMu0knsSUFW2DZXqKkGWlg      5   \n",
      "7        vcNAWiLM4dR7D2nwwJ7nCA 2014-01-08  onDPFgNZpMk-bT1zlForRA      5   \n",
      "8        JwUE5GmEO-sH1FuwJgKBlQ 2009-05-03  9uHZyOu5CTCDl1L6cfvOCA      4   \n",
      "9        JwUE5GmEO-sH1FuwJgKBlQ 2009-05-04  ow1c4Lcl3ObWxDC2yurwjQ      4   \n",
      "10       JwUE5GmEO-sH1FuwJgKBlQ 2010-10-30  FRTCszJWkJonDAZx3yr8FA      4   \n",
      "11       JwUE5GmEO-sH1FuwJgKBlQ 2011-02-06  qQIvtbqUujvvnJDzPSfmFA      4   \n",
      "12       JwUE5GmEO-sH1FuwJgKBlQ 2011-03-31  4iPPOQIo5Mr1NAUPUgCUrQ      4   \n",
      "13       JwUE5GmEO-sH1FuwJgKBlQ 2011-11-08  Rnm1KyfRcwNt9bOI5i-yqA      4   \n",
      "14       JwUE5GmEO-sH1FuwJgKBlQ 2011-12-29  SSlO5u2nIJ8PoAKAgN5m3Q      5   \n",
      "15       JwUE5GmEO-sH1FuwJgKBlQ 2012-01-08  _utPYHIdXeq8CqQ4iYD1bw      3   \n",
      "16       JwUE5GmEO-sH1FuwJgKBlQ 2012-01-08  6wFJ0Ml7r9elqjeoez3HXQ      4   \n",
      "17       JwUE5GmEO-sH1FuwJgKBlQ 2012-02-16  khGSK7FRLuRWnnTE6I0stA      4   \n",
      "18       JwUE5GmEO-sH1FuwJgKBlQ 2012-02-19  mdjs8GJUfqGajVMjgOrP5Q      4   \n",
      "19       JwUE5GmEO-sH1FuwJgKBlQ 2012-03-12  Vqkv071v8vLA2ux8aOeICQ      5   \n",
      "20       JwUE5GmEO-sH1FuwJgKBlQ 2012-08-26  gksnzyc9jQ9hNXESjvTrQw      3   \n",
      "21       JwUE5GmEO-sH1FuwJgKBlQ 2013-02-12  ilPs2w4liKDvlqLhWrkI8Q      4   \n",
      "22       JwUE5GmEO-sH1FuwJgKBlQ 2013-05-07  kAFG3i8DsfTkJePPEMc9Ig      5   \n",
      "23       JwUE5GmEO-sH1FuwJgKBlQ 2013-07-20  ue3D7WBI4ZQxH43wMdpfcA      3   \n",
      "24       JwUE5GmEO-sH1FuwJgKBlQ 2013-10-28  DAFwq9T6sKDYiyQHiAzVbQ      5   \n",
      "25       JwUE5GmEO-sH1FuwJgKBlQ 2014-03-13  PCa_K6ijV3Tzbp6nouEiJQ      4   \n",
      "26       JwUE5GmEO-sH1FuwJgKBlQ 2014-07-06  xpQe4tiCdZuQdmQsgtMErA      5   \n",
      "27       uGykseHzyS5xAMWoN6YUqA 2010-07-05  2owUZZsM0fuMNhzIfWcqRQ      4   \n",
      "28       uGykseHzyS5xAMWoN6YUqA 2010-10-19  BfPKrRDzpeQsljyxMa5sSA      5   \n",
      "29       uGykseHzyS5xAMWoN6YUqA 2010-12-04  HAFNOdoQEluZxGDshb7vOQ      5   \n",
      "...                         ...        ...                     ...    ...   \n",
      "1012883  yZXEELxi8KMwzXCHP345GQ 2014-07-08  a_HpoTGcxC_jVg5S0AA8Sw      5   \n",
      "1012884  yZXEELxi8KMwzXCHP345GQ 2014-07-09  XKhycgz8Dw0kEjR2ef-qpg      4   \n",
      "1012885  yZXEELxi8KMwzXCHP345GQ 2014-07-13  sKqxigDhZBWCqAzSSLrbIA      5   \n",
      "1012886  iyKyJoDcbkGrMCgvyfMHxw 2014-07-07  16Qc7Qau22Eb0u2uxhTSyA      5   \n",
      "1012887  iyKyJoDcbkGrMCgvyfMHxw 2014-07-12  wU180FiN1zdr-tIqBTzj9w      5   \n",
      "1012888  uUsfpN81JCMKyH6c0D0bTg 2014-07-08  5P35DoRIfKjOQSyAFmiZsw      4   \n",
      "1012889  uUsfpN81JCMKyH6c0D0bTg 2014-07-12  VxHaQYEuZJdCFJq-t_0tPg      3   \n",
      "1012890  uUsfpN81JCMKyH6c0D0bTg 2014-07-14  q0Kc-RYeVsKljJmAtjnDIw      5   \n",
      "1012891  uUsfpN81JCMKyH6c0D0bTg 2014-07-14  EF8uqLEP2RfRBF1G4UH9ZA      4   \n",
      "1012892  tsvWY4o64xiv7K0VA89R8A 2014-07-15  0w5slU3gLQVHS9J2AKKs4Q      5   \n",
      "1012893  tsvWY4o64xiv7K0VA89R8A 2014-07-15  vJyFNcjHKnrYCQAZAjY1zA      5   \n",
      "1012894  tsvWY4o64xiv7K0VA89R8A 2014-07-16  ZobzySQ_WZzh_vjcQU28dw      5   \n",
      "1012895  nYer89hXYAoddMEKTxw7kA 2014-07-15  b0qnZJuoPJvcKLwrC_84IQ      5   \n",
      "1012896  nYer89hXYAoddMEKTxw7kA 2014-07-15  Yykz_Z6E1koL6Ef83cOgQQ      5   \n",
      "1012897  nYer89hXYAoddMEKTxw7kA 2014-07-15  LI84TDkSPQ25oAbySweIJg      5   \n",
      "1012898  nYer89hXYAoddMEKTxw7kA 2014-07-15  lYb2U5Y-Szs9X5UqX6_xpw      5   \n",
      "1012899  nYer89hXYAoddMEKTxw7kA 2014-07-16  7qqYswBRx0yqP0Du_9xlDg      5   \n",
      "1012900  nYer89hXYAoddMEKTxw7kA 2014-07-16  7j9DJ0R2ys9N7PB2hZdceQ      5   \n",
      "1012901  nYer89hXYAoddMEKTxw7kA 2014-07-16  OO6prfuGEMalQcQcU3WCaw      5   \n",
      "1012902  nYer89hXYAoddMEKTxw7kA 2014-07-16  2fPxXAysOrZLrahZQyJCNg      5   \n",
      "1012903  nYer89hXYAoddMEKTxw7kA 2014-07-16  XXblLOSqYlq0tXhxHfXUHQ      4   \n",
      "1012904  nYer89hXYAoddMEKTxw7kA 2014-07-16  g8CIKUaosLDS3Vg7VLognA      5   \n",
      "1012905  BMjggIgOghBMEXPo8q7q3w 2014-07-10  4ffWpUCyITEgZEGGyZWhbA      5   \n",
      "1012906  BMjggIgOghBMEXPo8q7q3w 2014-07-16  vZVRzaoK2Z6C0-pd0YV9nw      5   \n",
      "1012907  BMjggIgOghBMEXPo8q7q3w 2014-07-16  FOIB5Cx_iIY-FWKMH45VRw      5   \n",
      "1012908  BVxlrYWgmi-8TPGMe6CTpg 2010-08-11  eujuvkGqy2ssZ9zjdPJrMA      5   \n",
      "1012909  BVxlrYWgmi-8TPGMe6CTpg 2012-06-15  vFA5KXUGEH-oMcM6WTC-8w      5   \n",
      "1012910  BVxlrYWgmi-8TPGMe6CTpg 2013-09-17  0sVK4VUxvj3cy78W0DlvWQ      3   \n",
      "1012911  BVxlrYWgmi-8TPGMe6CTpg 2013-09-18  Nx88b_tCsP7Oja3PvhR5tQ      4   \n",
      "1012912  BVxlrYWgmi-8TPGMe6CTpg 2013-12-17  p2KCsYuLHDtXqh1BpR9dGQ      3   \n",
      "\n",
      "                                                      text    type  \\\n",
      "0        dr. goldberg offers everything i look for in a...  review   \n",
      "1        Unfortunately, the frustration of being Dr. Go...  review   \n",
      "2        Dr. Goldberg has been my doctor for years and ...  review   \n",
      "3        Been going to Dr. Goldberg for over 10 years. ...  review   \n",
      "4        Got a letter in the mail last week that said D...  review   \n",
      "5        I don't know what Dr. Goldberg was like before...  review   \n",
      "6        Top notch doctor in a top notch practice. Can'...  review   \n",
      "7        Dr. Eric Goldberg is a fantastic doctor who ha...  review   \n",
      "8        Good truck stop dining at the right price. We ...  review   \n",
      "9        If you like lot lizards, you'll love the Pine ...  review   \n",
      "10       Enjoyable experience for the whole family. The...  review   \n",
      "11       One of my favorite truck stop diners with soli...  review   \n",
      "12       Only went here once about a year and a half ag...  review   \n",
      "13       Great truck stop restaurant.  I've had breakfa...  review   \n",
      "14       Yeah, thats right a five freakin star rating. ...  review   \n",
      "15       Ate a Saturday morning breakfast at the Pine C...  review   \n",
      "16       Attention fans of David Lynch.  Do stop by thi...  review   \n",
      "17       With a recent addition of a truck driver for a...  review   \n",
      "18       This is one of the best breakfasts I have had!...  review   \n",
      "19       hands down one of the best breakfasts my wife ...  review   \n",
      "20       This is definitely not your usual truck stop. ...  review   \n",
      "21       A delicious breakfast.  Amazing fresh bakery a...  review   \n",
      "22       Don't be fooled because it's in a truck stop, ...  review   \n",
      "23       Continuing on my Saturday morning hangover the...  review   \n",
      "24       Some times Jane and Michael Stern are on point...  review   \n",
      "25       I like this location better than the one near ...  review   \n",
      "26       OMG!  The bakery items at Pinecone are AMAZING...  review   \n",
      "27       A really lovely surprise on a rather horrific ...  review   \n",
      "28       Very nice and clean place to have breakfast or...  review   \n",
      "29       I eat here regularily because it is consistent...  review   \n",
      "...                                                    ...     ...   \n",
      "1012883  Wonderful service very delicious and healthy. ...  review   \n",
      "1012884  These guys are really close to a 5 star.  Ther...  review   \n",
      "1012885  I had the seafood kabob. It was very tasty sal...  review   \n",
      "1012886  Great hookah excellent service and awesome fla...  review   \n",
      "1012887  New owners very clean now and a great place to...  review   \n",
      "1012888  Third times a charm? This makes three times I ...  review   \n",
      "1012889  I called in a lunch order to go. The service w...  review   \n",
      "1012890  Ive never had bad pizza or pasta here.  Very a...  review   \n",
      "1012891  3.5 stars.\\n\\nTried this place for dinner and ...  review   \n",
      "1012892  I LOVE Pilates Central.  The studio is clean a...  review   \n",
      "1012893  I LOVE Pilates Central! They offer multiple cl...  review   \n",
      "1012894  Vanessa is an accomplished trainer and a life-...  review   \n",
      "1012895  Great theatre with a retro feel. Grab a glass ...  review   \n",
      "1012896  Oh my gosh! We got to see Wayne's World! FilmB...  review   \n",
      "1012897  That was awesome!\\n\\nShow up, see some friends...  review   \n",
      "1012898  What a wonderful idea for a monthly film serie...  review   \n",
      "1012899  Really enjoyed drinking wine and watching Wayn...  review   \n",
      "1012900  WAYNE'S WORLD! WAYNE'S WORLD! Party time! Exce...  review   \n",
      "1012901  Fab concept:\\n\\n- Test out a new (well, new fo...  review   \n",
      "1012902  Wayne's World....Short Leash...at the FilmBar....  review   \n",
      "1012903  Great Time!! Funny movie!! Loved going to the ...  review   \n",
      "1012904  What a horrible time yesterday... shYEAH - and...  review   \n",
      "1012905  My new favorite restaurant.  They have 22 diff...  review   \n",
      "1012906  GreAt food awesome service . The best fish in ...  review   \n",
      "1012907  Walking into this place looks nice and well ke...  review   \n",
      "1012908  Located at the bottom of Lauriston Place, this...  review   \n",
      "1012909  I love this place! I think the staff struggle ...  review   \n",
      "1012910  Perfect little shop to go to if you want to pi...  review   \n",
      "1012911  I visit here once or twice a month. Just to ge...  review   \n",
      "1012912  I like this place to pick up a few odds and en...  review   \n",
      "\n",
      "                        user_id                                       votes  \n",
      "0        Xqd0DzHaiyRqVH3WRG7hzg     {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
      "1        H1kH6QZV7Le4zqTRNxoZow     {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "2        zvJCcrpm2yOZrxKffwGQLA     {u'funny': 0, u'useful': 1, u'cool': 1}  \n",
      "3        KBLW4wJA_fwoWmMhiHRVOA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "4        zvJCcrpm2yOZrxKffwGQLA     {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
      "5        Qrs3EICADUKNFoUq2iHStA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "6        jE5xVugujSaskAoh2DRx3Q     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "7        QnhQ8G51XbUpVEyWY2Km-A     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "8        p4ySEi8PEli0auZGBsy6gA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "9        ZYaumz29bl9qHpu-KVtMGA     {u'funny': 6, u'useful': 0, u'cool': 0}  \n",
      "10       SvS7NXWG2B2kFoaHaWdGfg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "11       qOYI9O0ecMJ9VaqcM9phNw     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "12       EEYwj6_t1OT5WQGypqEPNg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "13       bfww9ItvUBeRsFQ4UD4eaw     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "14       Au3Qs-AAZEWu2_4gIMwRgw     {u'funny': 2, u'useful': 5, u'cool': 0}  \n",
      "15       MnXcXwr0keJpkIiwuPsOKg     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "16       -hwN2juKYn-KTxa2WBYLnw     {u'funny': 1, u'useful': 1, u'cool': 0}  \n",
      "17       pgKOL4k5tWCWS9VIc33EoQ     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "18       4K7YXIl77EOHlTfSUjLCDw     {u'funny': 1, u'useful': 0, u'cool': 0}  \n",
      "19       MDiCwtVo-Aq9cD5bAKd8Lw     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "20       wC8r-m6KHifL6R2i8ok8yg     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "21       4ih20jNIEPIkhkh-uxeyAg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "22       Bld8sdbL48rJzVXo4yMYWA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "23       OtpHvQFGbZ4sONaQAXankg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "24       nJ_6gzvBj0mF943eWZ0cSw     {u'funny': 1, u'useful': 0, u'cool': 0}  \n",
      "25       RvweNJFVkR3ttkWsIBy7nQ     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "26       LDrpATl7viHfGGeUKzPeZA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "27       vEc7evQDo09ttI3HA9655Q     {u'funny': 0, u'useful': 1, u'cool': 1}  \n",
      "28       8lvmjewvLCwnbfwNoE-Xyg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "29       u5xcw6LCnnMhddoxkRIgUA     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "...                         ...                                         ...  \n",
      "1012883  47bynM7RigcfKYdqLwLrOg     {u'funny': 0, u'useful': 0, u'cool': 1}  \n",
      "1012884  5pn0Rb0RSvt7IkPLWsGeZg     {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "1012885  0OcgBUzkRWm5s0eJF6eqiA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012886  fhsYXEXNNPxNiTg9toXm-w     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012887  c4CZvUnkyWdLnkF8FCwEkQ     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012888  2HmHgW3hRYvXYFmQyQtLuw  {u'funny': 27, u'useful': 34, u'cool': 30}  \n",
      "1012889  PTY5DM38QqeqbKSyfb9lww     {u'funny': 2, u'useful': 1, u'cool': 1}  \n",
      "1012890  1fgKqvcZbFpY7sbgCxxyvA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012891  11QzsQ-nmRykVvD4agGRPw     {u'funny': 5, u'useful': 7, u'cool': 7}  \n",
      "1012892  ijzoC48CQpHj0_vIJQ7lXw     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012893  6u2XSHbsJMA7LutItY-_3w     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012894  VCoIiPCv_bBDgw2RRU5kzA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012895  ofPkm7BTBJeaD0OkmZNdNQ     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012896  gzJpPaHN-NXBkAZcZri3hw   {u'funny': 8, u'useful': 12, u'cool': 10}  \n",
      "1012897  45V7-1r79DEG0HbuaKYIlg     {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
      "1012898  tBvrnSCLSpUdCDm5w5GPkg     {u'funny': 0, u'useful': 0, u'cool': 1}  \n",
      "1012899  9ebaAGLVIgGKpDLFwmvaiQ     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012900  H_JsAwjiGEOr_RlZmwfNsA     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "1012901  XTFE2ERq7YvaqGUgQYzVNA     {u'funny': 4, u'useful': 5, u'cool': 6}  \n",
      "1012902  usQTOj7LQ9v0Fl98gRa3Iw     {u'funny': 1, u'useful': 1, u'cool': 2}  \n",
      "1012903  hdZ3rlgFXctCOUhzoOebvA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012904  wy8Yd_vCWDjiz9rMo4HfqA     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012905  AnH84g9V10x41CXmCvcaFg     {u'funny': 0, u'useful': 2, u'cool': 0}  \n",
      "1012906  pslJujFe9XO28lMm8izNtg     {u'funny': 0, u'useful': 0, u'cool': 0}  \n",
      "1012907  ZVkaYRCTFSSt-Ch9uwigOQ     {u'funny': 0, u'useful': 0, u'cool': 1}  \n",
      "1012908  lhMo-dGq0V2iKqBIiwUJSg     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "1012909  TTrzXCtB2MZA8Azw56bRlw     {u'funny': 2, u'useful': 1, u'cool': 1}  \n",
      "1012910  rtS7mDof5d-cEPBsmVuUJw     {u'funny': 0, u'useful': 2, u'cool': 1}  \n",
      "1012911  tZs84cKAUSOtP_nAiSdreQ     {u'funny': 1, u'useful': 1, u'cool': 1}  \n",
      "1012912  LfnB4N7SVSAIPOM3If_kDA     {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
      "\n",
      "[1012913 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Type:', <class 'pandas.core.frame.DataFrame'>)\n",
      "(1012913, 8)\n"
     ]
    }
   ],
   "source": [
    "# properties of original data\n",
    "print('Type:',type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features:', Index([u'business_id', u'date', u'review_id', u'stars', u'text', u'type',\n",
      "       u'user_id', u'votes'],\n",
      "      dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "print('Features:', data.keys())  # print all the features available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012913, 2)\n",
      "('Features:', Index([u'stars', u'text'], dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "# dropping the unnecessary features from pandas\n",
    "\n",
    "feature_to_drop=set(data.columns.values)-set(['stars','text'])\n",
    "data.drop(columns=list(feature_to_drop),inplace=True)\n",
    "pprint(data.shape)\n",
    "print('Features:', data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features:', Index([u'goodness', u'text'], dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "#renaming the features stars as goodness and text as \n",
    "data.rename(columns={'stars':'goodness'}, inplace=True)\n",
    "print('Features:', data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         goodness                                               text\n",
      "0               5  dr. goldberg offers everything i look for in a...\n",
      "1               2  Unfortunately, the frustration of being Dr. Go...\n",
      "2               4  Dr. Goldberg has been my doctor for years and ...\n",
      "3               4  Been going to Dr. Goldberg for over 10 years. ...\n",
      "4               4  Got a letter in the mail last week that said D...\n",
      "5               1  I don't know what Dr. Goldberg was like before...\n",
      "6               5  Top notch doctor in a top notch practice. Can'...\n",
      "7               5  Dr. Eric Goldberg is a fantastic doctor who ha...\n",
      "8               4  Good truck stop dining at the right price. We ...\n",
      "9               4  If you like lot lizards, you'll love the Pine ...\n",
      "10              4  Enjoyable experience for the whole family. The...\n",
      "11              4  One of my favorite truck stop diners with soli...\n",
      "12              4  Only went here once about a year and a half ag...\n",
      "13              4  Great truck stop restaurant.  I've had breakfa...\n",
      "14              5  Yeah, thats right a five freakin star rating. ...\n",
      "15              3  Ate a Saturday morning breakfast at the Pine C...\n",
      "16              4  Attention fans of David Lynch.  Do stop by thi...\n",
      "17              4  With a recent addition of a truck driver for a...\n",
      "18              4  This is one of the best breakfasts I have had!...\n",
      "19              5  hands down one of the best breakfasts my wife ...\n",
      "20              3  This is definitely not your usual truck stop. ...\n",
      "21              4  A delicious breakfast.  Amazing fresh bakery a...\n",
      "22              5  Don't be fooled because it's in a truck stop, ...\n",
      "23              3  Continuing on my Saturday morning hangover the...\n",
      "24              5  Some times Jane and Michael Stern are on point...\n",
      "25              4  I like this location better than the one near ...\n",
      "26              5  OMG!  The bakery items at Pinecone are AMAZING...\n",
      "27              4  A really lovely surprise on a rather horrific ...\n",
      "28              5  Very nice and clean place to have breakfast or...\n",
      "29              5  I eat here regularily because it is consistent...\n",
      "...           ...                                                ...\n",
      "1012883         5  Wonderful service very delicious and healthy. ...\n",
      "1012884         4  These guys are really close to a 5 star.  Ther...\n",
      "1012885         5  I had the seafood kabob. It was very tasty sal...\n",
      "1012886         5  Great hookah excellent service and awesome fla...\n",
      "1012887         5  New owners very clean now and a great place to...\n",
      "1012888         4  Third times a charm? This makes three times I ...\n",
      "1012889         3  I called in a lunch order to go. The service w...\n",
      "1012890         5  Ive never had bad pizza or pasta here.  Very a...\n",
      "1012891         4  3.5 stars.\\n\\nTried this place for dinner and ...\n",
      "1012892         5  I LOVE Pilates Central.  The studio is clean a...\n",
      "1012893         5  I LOVE Pilates Central! They offer multiple cl...\n",
      "1012894         5  Vanessa is an accomplished trainer and a life-...\n",
      "1012895         5  Great theatre with a retro feel. Grab a glass ...\n",
      "1012896         5  Oh my gosh! We got to see Wayne's World! FilmB...\n",
      "1012897         5  That was awesome!\\n\\nShow up, see some friends...\n",
      "1012898         5  What a wonderful idea for a monthly film serie...\n",
      "1012899         5  Really enjoyed drinking wine and watching Wayn...\n",
      "1012900         5  WAYNE'S WORLD! WAYNE'S WORLD! Party time! Exce...\n",
      "1012901         5  Fab concept:\\n\\n- Test out a new (well, new fo...\n",
      "1012902         5  Wayne's World....Short Leash...at the FilmBar....\n",
      "1012903         4  Great Time!! Funny movie!! Loved going to the ...\n",
      "1012904         5  What a horrible time yesterday... shYEAH - and...\n",
      "1012905         5  My new favorite restaurant.  They have 22 diff...\n",
      "1012906         5  GreAt food awesome service . The best fish in ...\n",
      "1012907         5  Walking into this place looks nice and well ke...\n",
      "1012908         5  Located at the bottom of Lauriston Place, this...\n",
      "1012909         5  I love this place! I think the staff struggle ...\n",
      "1012910         3  Perfect little shop to go to if you want to pi...\n",
      "1012911         4  I visit here once or twice a month. Just to ge...\n",
      "1012912         3  I like this place to pick up a few odds and en...\n",
      "\n",
      "[1012913 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(stars):\n",
    "    if stars>2:\n",
    "        return True\n",
    "    else:\n",
    "        return False  \n",
    "\n",
    "# For the function to go through each element and make changes according to the value, We will use lamda function\n",
    "data['goodness']=data['goodness'].apply(lambda x: convert(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         goodness                                               text\n",
      "0            True  dr. goldberg offers everything i look for in a...\n",
      "1           False  Unfortunately, the frustration of being Dr. Go...\n",
      "2            True  Dr. Goldberg has been my doctor for years and ...\n",
      "3            True  Been going to Dr. Goldberg for over 10 years. ...\n",
      "4            True  Got a letter in the mail last week that said D...\n",
      "5           False  I don't know what Dr. Goldberg was like before...\n",
      "6            True  Top notch doctor in a top notch practice. Can'...\n",
      "7            True  Dr. Eric Goldberg is a fantastic doctor who ha...\n",
      "8            True  Good truck stop dining at the right price. We ...\n",
      "9            True  If you like lot lizards, you'll love the Pine ...\n",
      "10           True  Enjoyable experience for the whole family. The...\n",
      "11           True  One of my favorite truck stop diners with soli...\n",
      "12           True  Only went here once about a year and a half ag...\n",
      "13           True  Great truck stop restaurant.  I've had breakfa...\n",
      "14           True  Yeah, thats right a five freakin star rating. ...\n",
      "15           True  Ate a Saturday morning breakfast at the Pine C...\n",
      "16           True  Attention fans of David Lynch.  Do stop by thi...\n",
      "17           True  With a recent addition of a truck driver for a...\n",
      "18           True  This is one of the best breakfasts I have had!...\n",
      "19           True  hands down one of the best breakfasts my wife ...\n",
      "20           True  This is definitely not your usual truck stop. ...\n",
      "21           True  A delicious breakfast.  Amazing fresh bakery a...\n",
      "22           True  Don't be fooled because it's in a truck stop, ...\n",
      "23           True  Continuing on my Saturday morning hangover the...\n",
      "24           True  Some times Jane and Michael Stern are on point...\n",
      "25           True  I like this location better than the one near ...\n",
      "26           True  OMG!  The bakery items at Pinecone are AMAZING...\n",
      "27           True  A really lovely surprise on a rather horrific ...\n",
      "28           True  Very nice and clean place to have breakfast or...\n",
      "29           True  I eat here regularily because it is consistent...\n",
      "...           ...                                                ...\n",
      "1012883      True  Wonderful service very delicious and healthy. ...\n",
      "1012884      True  These guys are really close to a 5 star.  Ther...\n",
      "1012885      True  I had the seafood kabob. It was very tasty sal...\n",
      "1012886      True  Great hookah excellent service and awesome fla...\n",
      "1012887      True  New owners very clean now and a great place to...\n",
      "1012888      True  Third times a charm? This makes three times I ...\n",
      "1012889      True  I called in a lunch order to go. The service w...\n",
      "1012890      True  Ive never had bad pizza or pasta here.  Very a...\n",
      "1012891      True  3.5 stars.\\n\\nTried this place for dinner and ...\n",
      "1012892      True  I LOVE Pilates Central.  The studio is clean a...\n",
      "1012893      True  I LOVE Pilates Central! They offer multiple cl...\n",
      "1012894      True  Vanessa is an accomplished trainer and a life-...\n",
      "1012895      True  Great theatre with a retro feel. Grab a glass ...\n",
      "1012896      True  Oh my gosh! We got to see Wayne's World! FilmB...\n",
      "1012897      True  That was awesome!\\n\\nShow up, see some friends...\n",
      "1012898      True  What a wonderful idea for a monthly film serie...\n",
      "1012899      True  Really enjoyed drinking wine and watching Wayn...\n",
      "1012900      True  WAYNE'S WORLD! WAYNE'S WORLD! Party time! Exce...\n",
      "1012901      True  Fab concept:\\n\\n- Test out a new (well, new fo...\n",
      "1012902      True  Wayne's World....Short Leash...at the FilmBar....\n",
      "1012903      True  Great Time!! Funny movie!! Loved going to the ...\n",
      "1012904      True  What a horrible time yesterday... shYEAH - and...\n",
      "1012905      True  My new favorite restaurant.  They have 22 diff...\n",
      "1012906      True  GreAt food awesome service . The best fish in ...\n",
      "1012907      True  Walking into this place looks nice and well ke...\n",
      "1012908      True  Located at the bottom of Lauriston Place, this...\n",
      "1012909      True  I love this place! I think the staff struggle ...\n",
      "1012910      True  Perfect little shop to go to if you want to pi...\n",
      "1012911      True  I visit here once or twice a month. Just to ge...\n",
      "1012912      True  I like this place to pick up a few odds and en...\n",
      "\n",
      "[1012913 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\n"
     ]
    }
   ],
   "source": [
    "#the text is with both lower and upper case letter we have to convert all the letters to lower case letter \n",
    "print(data['text'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace upper case letter with lower case letter using regula expression module\n",
    "# print(data_tmp['text'].iloc[0],'\\n')\n",
    "data['text']=data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been going to dr. goldberg for over 10 years. i think i was one of his 1st patients when he started at mhmg. he's been great over the years and is really all about the big picture. it is because of him, not my now former gyn dr. markoff, that i found out i have fibroids. he explores all options with you and is very patient and understanding. he doesn't judge and asks all the right questions. very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\n"
     ]
    }
   ],
   "source": [
    "#we can see the upper case letters has been turned to lower case letter\n",
    "print(data['text'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Punchuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['(', ')', '?', ':', ':', ',', '.', '!', '/', '\"', \"'\"]\n",
    "for i in punctuation:\n",
    "    data['text'] = data['text'].str.replace(i, '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been going to dr goldberg for over 10 years i think i was one of his 1st patients when he started at mhmg hes been great over the years and is really all about the big picture it is because of him not my now former gyn dr markoff that i found out i have fibroids he explores all options with you and is very patient and understanding he doesnt judge and asks all the right questions very thorough and wants to be kept in the loop on every aspect of your medical health and your life\n"
     ]
    }
   ],
   "source": [
    "print(data['text'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ratio of the tags. It is told 80% as per the manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('good:', 820907)\n",
      "('Bad;', 192006)\n",
      "('relative ratio', 4)\n"
     ]
    }
   ],
   "source": [
    "good = np.count_nonzero(data['goodness'])\n",
    "bad = len(data) - good\n",
    "print('good:', good)\n",
    "print('Bad;', bad)\n",
    "print('relative ratio', good/bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the data set is not balanced , there are two ways to take care of it. First is to create a data set which is balanced then work with or during the analysis incorporate this uunbalanced factor. Here I will be taking the unbalanced factor into account while doing my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will be working a smaller subset to make it faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Subset in use', 202582, 202582)\n",
      "('Unused subset', 810331, 810331)\n",
      "('Training size:', 162065, 162065)\n",
      "('Test size:', 40517, 40517)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text =  data['text']\n",
    "goodness = data['goodness']\n",
    "\n",
    "xsubset, x_unused, ysubset, y_unused = train_test_split(text, goodness, test_size=0.8, random_state=42)\n",
    "\n",
    "# I am taking fraction of a fraction for the real training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(xsubset, ysubset, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Subset in use\", len(xsubset),len(ysubset))\n",
    "print(\"Unused subset\", len(x_unused),len(y_unused))\n",
    "print(\"Training size:\", len(x_train),len(y_train))\n",
    "print(\"Test size:\", len(x_test),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162065, 156710)\n",
      "156710\n",
      "(1, 156710)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# for data exploration \n",
    "cv = CountVectorizer()\n",
    "train_cv = cv.fit_transform(x_train)\n",
    "\n",
    "print train_cv.shape\n",
    "print len(cv.vocabulary_)\n",
    "\n",
    "total_word_count = train_cv.sum(axis = 0)\n",
    "print total_word_count.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162065, 156710)\n",
      "156710\n",
      "(1, 156710)\n",
      "Most frequent words:\n",
      "         1 the           1079320\n",
      "         2 and            691012\n",
      "         3 to             497984\n",
      "         4 was            353611\n",
      "         5 of             324274\n",
      "         6 it             274193\n",
      "         7 is             257811\n",
      "         8 in             244860\n",
      "         9 for            244844\n",
      "        10 that           185452\n",
      "        11 my             182472\n",
      "        12 with           168912\n",
      "        13 but            167098\n",
      "        14 this           166539\n",
      "        15 we             163760\n",
      "        16 you            163555\n",
      "        17 they           151156\n",
      "        18 on             148350\n",
      "        19 have           132477\n",
      "        20 not            122814\n",
      "        21 had            119285\n",
      "        22 so             112162\n",
      "        23 at             110940\n",
      "        24 were           109087\n",
      "        25 are            104406\n",
      "        26 good            99411\n",
      "        27 place           95586\n",
      "        28 food            89983\n",
      "        29 as              89317\n",
      "        30 be              86612\n",
      "        31 there           82706\n",
      "        32 all             77736\n",
      "        33 great           75893\n",
      "        34 like            75635\n",
      "        35 if              75333\n",
      "        36 me              74897\n",
      "        37 out             72830\n",
      "        38 very            72811\n",
      "        39 its             71070\n",
      "        40 here            70583\n",
      "        41 just            70268\n",
      "        42 one             65749\n",
      "        43 get             65148\n",
      "        44 our             61934\n",
      "        45 from            59760\n",
      "        46 time            59236\n",
      "        47 or              57692\n",
      "        48 their           57031\n",
      "        49 when            56813\n",
      "        50 up              56286\n"
     ]
    }
   ],
   "source": [
    "print train_cv.shape\n",
    "print len(cv.vocabulary_)\n",
    "\n",
    "total_word_count = train_cv.sum(axis = 0)\n",
    "print total_word_count.shape\n",
    "\n",
    "print \"Most frequent words:\"\n",
    "for idx in xrange(1,51):\n",
    "    vocabulary_index = total_word_count.argsort(axis=1)[0,-1*idx]\n",
    "    word = cv.get_feature_names()[vocabulary_index]\n",
    "    print \"{0:10} {1:10} {2:10}\".format(idx,word,total_word_count[0,vocabulary_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the stop words from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding more stop words manually\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_stop_words = ['time','great','ive','really','im','dont','didnt','came,''food','going','just','got','did']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162065, 156390)\n",
      "156390\n",
      "(1, 156390)\n",
      "Most frequent words:\n",
      "         1 good            99411\n",
      "         2 place           95586\n",
      "         3 food            89983\n",
      "         4 like            75635\n",
      "         5 service         55778\n",
      "         6 nice            35974\n",
      "         7 best            31796\n",
      "         8 love            31395\n",
      "         9 little          30373\n",
      "        10 vegas           29569\n",
      "        11 ordered         27761\n",
      "        12 people          27403\n",
      "        13 pretty          27163\n",
      "        14 try             26654\n",
      "        15 went            26463\n",
      "        16 restaurant      26267\n",
      "        17 order           25660\n",
      "        18 came            25591\n",
      "        19 chicken         23764\n",
      "        20 menu            23591\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=set(stop_words))\n",
    "train_cv = cv.fit_transform(x_train)\n",
    "\n",
    "print (train_cv.shape)\n",
    "print (len(cv.vocabulary_))\n",
    "\n",
    "total_word_count = train_cv.sum(axis = 0)\n",
    "print (total_word_count.shape)\n",
    "\n",
    "print (\"Most frequent words:\")\n",
    "for idx in range(1,21):\n",
    "    vocabulary_index = total_word_count.argsort(axis=1)[0,-1*idx]\n",
    "    word = cv.get_feature_names()[vocabulary_index]\n",
    "    print (\"{0:10} {1:10} {2:10}\".format(idx,word,total_word_count[0,vocabulary_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more parameters max_df, min_df to remove more words from the file which appear very few places ot too many place or too few places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162065, 23554)\n",
      "23554\n",
      "(1, 23554)\n",
      "Most frequent words:\n",
      "         1 good            99411\n",
      "         2 place           95586\n",
      "         3 food            89983\n",
      "         4 like            75635\n",
      "         5 service         55778\n",
      "         6 nice            35974\n",
      "         7 best            31796\n",
      "         8 love            31395\n",
      "         9 little          30373\n",
      "        10 vegas           29569\n",
      "        11 ordered         27761\n",
      "        12 people          27403\n",
      "        13 pretty          27163\n",
      "        14 try             26654\n",
      "        15 went            26463\n",
      "        16 restaurant      26267\n",
      "        17 order           25660\n",
      "        18 came            25591\n",
      "        19 chicken         23764\n",
      "        20 menu            23591\n"
     ]
    }
   ],
   "source": [
    "# max_df When building the vocabulary ignore terms that have a document \n",
    "#frequency strictly higher than the given threshold or appears more than some thresold pecentage of the doc.\n",
    "#I am taking I think any value between 0.8-0.9 would be good measure\n",
    "\n",
    "#min_df represents the thresold that a word should minimally occure in the doc.\n",
    "\n",
    "cv = CountVectorizer(stop_words=set(stop_words),lowercase=True, max_df = 0.9,min_df = 10)\n",
    "train_cv = cv.fit_transform(x_train)\n",
    "\n",
    "print (train_cv.shape)\n",
    "print (len(cv.vocabulary_))\n",
    "\n",
    "total_word_count = train_cv.sum(axis = 0)\n",
    "print (total_word_count.shape)\n",
    "\n",
    "print (\"Most frequent words:\")\n",
    "for idx in range(1,21):\n",
    "    vocabulary_index = total_word_count.argsort(axis=1)[0,-1*idx]\n",
    "    word = cv.get_feature_names()[vocabulary_index]\n",
    "    print (\"{0:10} {1:10} {2:10}\".format(idx,word,total_word_count[0,vocabulary_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check how the frequency varying among the top ranked words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1 good            99411\n",
      "         2 place           95586\n",
      "         3 food            89983\n",
      "         4 like            75635\n",
      "         5 service         55778\n",
      "         6 nice            35974\n",
      "         7 best            31796\n",
      "         8 love            31395\n",
      "         9 little          30373\n",
      "        10 vegas           29569\n",
      "        11 ordered         27761\n",
      "        12 people          27403\n",
      "        13 pretty          27163\n",
      "        14 try             26654\n",
      "        15 went            26463\n",
      "        16 restaurant      26267\n",
      "        17 order           25660\n",
      "        18 came            25591\n",
      "        19 chicken         23764\n",
      "        20 menu            23591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6027a78dd0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank=[]\n",
    "freq=[]\n",
    "cv_top_20_words_position = {}\n",
    "for idx in range(1,21):\n",
    "    vocabulary_index = total_word_count.argsort(axis=1)[0,-1*idx]\n",
    "    word = cv.get_feature_names()[vocabulary_index]\n",
    "    print (\"{0:10} {1:10} {2:10}\".format(idx,word,total_word_count[0,vocabulary_index]))\n",
    "    rank.append(idx)\n",
    "    freq.append(total_word_count[0,vocabulary_index])\n",
    "    cv_top_20_words_position[word]=idx\n",
    "    \n",
    "plt.plot(rank, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF transformation\n",
    "A a logarithmic tf-idf approach is taken to refelct more meaningful behaviour of words which not just appear too many times in the document throughout the course of the document. So to weight the importance we use the TF-IDF transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162065, 23554)\n",
      "(1, 23554)\n",
      "Most frequent words:\n",
      "         1 food          5104.28 3         \n",
      "         2 good          5042.56 1         \n",
      "         3 place         4841.58 2         \n",
      "         4 service       3641.30 5         \n",
      "         5 like          3377.26 4         \n",
      "         6 love          2592.43 8         \n",
      "         7 best          2435.93 7         \n",
      "         8 nice          2413.10 6         \n",
      "         9 vegas         2058.48 10        \n",
      "        10 friendly      2020.18 -         \n",
      "        11 staff         1978.24 -         \n",
      "        12 little        1906.06 9         \n",
      "        13 try           1830.74 14        \n",
      "        14 pretty        1827.53 13        \n",
      "        15 chicken       1816.57 19        \n",
      "        16 pizza         1808.17 -         \n",
      "        17 restaurant    1794.49 16        \n",
      "        18 amazing       1762.07 -         \n",
      "        19 ordered       1735.33 11        \n",
      "        20 people        1730.38 12        \n",
      "        21 went          1726.64 15        \n",
      "        22 better        1694.22 -         \n",
      "        23 order         1684.58 17        \n",
      "        24 delicious     1684.29 -         \n",
      "        25 definitely    1679.37 -         \n",
      "        26 bar           1639.52 -         \n",
      "        27 menu          1613.65 20        \n",
      "        28 come          1612.54 -         \n",
      "        29 came          1573.58 18        \n",
      "        30 night         1551.88 -         \n",
      "        31 awesome       1503.99 -         \n",
      "        32 eat           1490.05 -         \n",
      "        33 make          1481.66 -         \n",
      "        34 way           1452.96 -         \n",
      "        35 wait          1451.89 -         \n",
      "        36 lunch         1450.17 -         \n",
      "        37 know          1425.92 -         \n",
      "        38 room          1410.97 -         \n",
      "        39 fresh         1400.99 -         \n",
      "        40 think         1388.62 -         \n",
      "        41 right         1385.18 -         \n",
      "        42 experience    1374.83 -         \n",
      "        43 want          1369.97 -         \n",
      "        44 price         1366.24 -         \n",
      "        45 say           1360.26 -         \n",
      "        46 new           1343.20 -         \n",
      "        47 day           1324.57 -         \n",
      "        48 bad           1321.20 -         \n",
      "        49 prices        1292.06 -         \n",
      "        50 sure          1290.15 -         \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "train_tfidf = tfidf.fit_transform(train_cv)\n",
    "print train_tfidf.shape\n",
    "\n",
    "total_word_tfidf = train_tfidf.sum(axis = 0)\n",
    "print total_word_tfidf.shape\n",
    "\n",
    "\n",
    "print \"Most frequent words:\"\n",
    "for idx in xrange(1,51):\n",
    "    vocabulary_index = total_word_tfidf.argsort(axis=1)[0,-1*idx]\n",
    "    word = cv.get_feature_names()[vocabulary_index]\n",
    "    old_position = '-'\n",
    "    if word in cv_top_20_words_position:\n",
    "        old_position=str(cv_top_20_words_position[word])\n",
    "    print \"{0:10} {1:10} {2:10.2f} {3:10}\".format(idx,word,float(total_word_tfidf[0,vocabulary_index]),old_position)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a lot of new word popping up which were not in the top frequency chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini', # the cut at each node is defined by estimator\n",
    "                            splitter='best', \n",
    "                            max_depth=None, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, \n",
    "                            max_features=None, \n",
    "                            random_state=1, \n",
    "                            max_leaf_nodes=None, \n",
    "                            class_weight=None, \n",
    "                            presort=False)\n",
    "\n",
    "dt.fit(train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the training set is: 0.99979020763274\n"
     ]
    }
   ],
   "source": [
    "score_train = dt.score(train_tfidf,y_train)\n",
    "print \"The accuracy of the model on the training set is:\",score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the training set is: 0.8256781104227855\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_cv = cv.transform(x_test)\n",
    "test_tfidf = tfidf.transform(test_cv)\n",
    "\n",
    "score_test = dt.score(test_tfidf,y_test)\n",
    "print \"The accuracy of the model on the training set is:\",score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Optimise the model and Industrialise and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "#### It enables us to use the transformations and the analysis step to be merged together into one step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to decrese the min-df realizing the imporatant need to not to be scattered and abundent throughout\n",
    "pipe = pipeline.Pipeline([\n",
    "                            ('count_vectorizer',CountVectorizer(stop_words=stop_words,min_df=0.01,max_df=0.8)),\n",
    "                            ('model',DecisionTreeClassifier(criterion='gini',\n",
    "                            splitter='best',\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_weight_fraction_leaf=0.0, \n",
    "                            max_features=None, \n",
    "                            random_state=1,\n",
    "                            max_depth=None,\n",
    "                            max_leaf_nodes=None, \n",
    "                            class_weight=None, \n",
    "                            presort=False))\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=0.8, max_features=None, min_df=0.01,\n",
      "        ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=frozenset(['all', 'show', 'anyway', 'fifty', 'four', 'go', 'mill', 'find', 'seemed', 'whose', 're', 'herself', 'whoever', 'behind', 'should', 'dont', 'to', 'only', 'going', 'under', 'herein', 'do', 'his', 'get', 'very', 'de', 'myself', 'cannot', 'every', 'yourselves', 'him', 'is', 'did', ...st', 'eight', 'but', 'nothing', 'why', 'noone', 'sometimes', 'together', 'time', 'serious', 'once']),\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "count_vec_object = pipe.named_steps['count_vectorizer']\n",
    "print(count_vec_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and fitting through piplining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new training score is:', 0.9990744454385586)\n",
      "('new test score is:', 0.8065750178937237)\n"
     ]
    }
   ],
   "source": [
    "pipe = pipe.fit(x_train,y_train)\n",
    "score_train_pipe = pipe.score(x_train,y_train)\n",
    "score_test_pipe = pipe.score(x_test,y_test)\n",
    "print (\"new training score is:\",score_train_pipe)\n",
    "print (\"new test score is:\",score_test_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__min_samples_leaf': 55, 'model__min_samples_split': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_model__min_samples_leaf</th>\n",
       "      <th>param_model__min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.927865</td>\n",
       "      <td>14.251641</td>\n",
       "      <td>0.852431</td>\n",
       "      <td>0.888458</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'model__min_samples_leaf': 40, u'model__min_...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852872</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>0.851990</td>\n",
       "      <td>0.886587</td>\n",
       "      <td>2.445979</td>\n",
       "      <td>0.967029</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.739365</td>\n",
       "      <td>14.348140</td>\n",
       "      <td>0.852431</td>\n",
       "      <td>0.888458</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'model__min_samples_leaf': 40, u'model__min_...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852872</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>0.851990</td>\n",
       "      <td>0.886587</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.248440</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.987890</td>\n",
       "      <td>14.611287</td>\n",
       "      <td>0.852431</td>\n",
       "      <td>0.888458</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>{u'model__min_samples_leaf': 40, u'model__min_...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852872</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>0.851990</td>\n",
       "      <td>0.886587</td>\n",
       "      <td>1.271989</td>\n",
       "      <td>0.064970</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.110909</td>\n",
       "      <td>13.504802</td>\n",
       "      <td>0.853164</td>\n",
       "      <td>0.883364</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'model__min_samples_leaf': 50, u'model__min_...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.852548</td>\n",
       "      <td>0.885111</td>\n",
       "      <td>0.853779</td>\n",
       "      <td>0.881617</td>\n",
       "      <td>1.928839</td>\n",
       "      <td>0.143793</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.693763</td>\n",
       "      <td>12.685955</td>\n",
       "      <td>0.853164</td>\n",
       "      <td>0.883364</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'model__min_samples_leaf': 50, u'model__min_...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.852548</td>\n",
       "      <td>0.885111</td>\n",
       "      <td>0.853779</td>\n",
       "      <td>0.881617</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>0.167560</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47.172947</td>\n",
       "      <td>12.670586</td>\n",
       "      <td>0.853164</td>\n",
       "      <td>0.883364</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>{u'model__min_samples_leaf': 50, u'model__min_...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.852548</td>\n",
       "      <td>0.885111</td>\n",
       "      <td>0.853779</td>\n",
       "      <td>0.881617</td>\n",
       "      <td>0.733002</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.012858</td>\n",
       "      <td>12.699642</td>\n",
       "      <td>0.853666</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'model__min_samples_leaf': 55, u'model__min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853190</td>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>0.093329</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47.532528</td>\n",
       "      <td>13.094789</td>\n",
       "      <td>0.853666</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'model__min_samples_leaf': 55, u'model__min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853190</td>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>2.498084</td>\n",
       "      <td>0.445194</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.248718</td>\n",
       "      <td>13.888775</td>\n",
       "      <td>0.853666</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>{u'model__min_samples_leaf': 55, u'model__min_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853190</td>\n",
       "      <td>0.882468</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.364563</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.884409</td>\n",
       "      <td>13.918672</td>\n",
       "      <td>0.852957</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'model__min_samples_leaf': 60, u'model__min_...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.853398</td>\n",
       "      <td>0.880887</td>\n",
       "      <td>0.852516</td>\n",
       "      <td>0.877388</td>\n",
       "      <td>0.172686</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      59.927865        14.251641         0.852431          0.888458   \n",
       "1      56.739365        14.348140         0.852431          0.888458   \n",
       "2      56.987890        14.611287         0.852431          0.888458   \n",
       "3      54.110909        13.504802         0.853164          0.883364   \n",
       "4      46.693763        12.685955         0.853164          0.883364   \n",
       "5      47.172947        12.670586         0.853164          0.883364   \n",
       "6      45.012858        12.699642         0.853666          0.881197   \n",
       "7      47.532528        13.094789         0.853666          0.881197   \n",
       "8      48.248718        13.888775         0.853666          0.881197   \n",
       "9      45.884409        13.918672         0.852957          0.879137   \n",
       "\n",
       "  param_model__min_samples_leaf param_model__min_samples_split  \\\n",
       "0                            40                              2   \n",
       "1                            40                              3   \n",
       "2                            40                              4   \n",
       "3                            50                              2   \n",
       "4                            50                              3   \n",
       "5                            50                              4   \n",
       "6                            55                              2   \n",
       "7                            55                              3   \n",
       "8                            55                              4   \n",
       "9                            60                              2   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
       "1  {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
       "2  {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
       "3  {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
       "4  {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
       "5  {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
       "6  {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
       "7  {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
       "8  {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
       "9  {u'model__min_samples_leaf': 60, u'model__min_...                7   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.852872            0.890329           0.851990   \n",
       "1           0.852872            0.890329           0.851990   \n",
       "2           0.852872            0.890329           0.851990   \n",
       "3           0.852548            0.885111           0.853779   \n",
       "4           0.852548            0.885111           0.853779   \n",
       "5           0.852548            0.885111           0.853779   \n",
       "6           0.853190            0.882468           0.854142   \n",
       "7           0.853190            0.882468           0.854142   \n",
       "8           0.853190            0.882468           0.854142   \n",
       "9           0.853398            0.880887           0.852516   \n",
       "\n",
       "   split1_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.886587      2.445979        0.967029        0.000441   \n",
       "1            0.886587      0.710887        0.248440        0.000441   \n",
       "2            0.886587      1.271989        0.064970        0.000441   \n",
       "3            0.881617      1.928839        0.143793        0.000616   \n",
       "4            0.881617      0.491990        0.167560        0.000616   \n",
       "5            0.881617      0.733002        0.027418        0.000616   \n",
       "6            0.879926      0.093329        0.015243        0.000476   \n",
       "7            0.879926      2.498084        0.445194        0.000476   \n",
       "8            0.879926      0.351267        0.364563        0.000476   \n",
       "9            0.877388      0.172686        0.070588        0.000441   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.001871  \n",
       "1         0.001871  \n",
       "2         0.001871  \n",
       "3         0.001747  \n",
       "4         0.001747  \n",
       "5         0.001747  \n",
       "6         0.001271  \n",
       "7         0.001271  \n",
       "8         0.001271  \n",
       "9         0.001750  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minl_range=np.array([40,50,55,60])\n",
    "mins_range=[2,3,4]\n",
    "\n",
    "gs = GridSearchCV(pipe,{\"model__min_samples_leaf\": minl_range,\"model__min_samples_split\": mins_range,},\n",
    "                    cv=2, n_jobs=1, scoring='roc_auc' )\n",
    "\n",
    "# I am not able to run parallel so njob=1 otherwise it complains\n",
    "gs.fit(x_train,y_train)\n",
    "\n",
    "print gs.best_params_\n",
    "results = DataFrame(data = gs.cv_results_)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried a lot but I don't know how to solve this problem. I was not able ot run this on my laptop. I could solve the problem but now I have to run it in a single core. It complains when I try to run it parallelly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       59.927865        14.251641         0.852431          0.888458   \n",
      "1       56.739365        14.348140         0.852431          0.888458   \n",
      "2       56.987890        14.611287         0.852431          0.888458   \n",
      "3       54.110909        13.504802         0.853164          0.883364   \n",
      "4       46.693763        12.685955         0.853164          0.883364   \n",
      "5       47.172947        12.670586         0.853164          0.883364   \n",
      "6       45.012858        12.699642         0.853666          0.881197   \n",
      "7       47.532528        13.094789         0.853666          0.881197   \n",
      "8       48.248718        13.888775         0.853666          0.881197   \n",
      "9       45.884409        13.918672         0.852957          0.879137   \n",
      "10      46.357903        13.914288         0.852957          0.879137   \n",
      "11      45.692410        13.809545         0.852957          0.879137   \n",
      "\n",
      "   param_model__min_samples_leaf param_model__min_samples_split  \\\n",
      "0                             40                              2   \n",
      "1                             40                              3   \n",
      "2                             40                              4   \n",
      "3                             50                              2   \n",
      "4                             50                              3   \n",
      "5                             50                              4   \n",
      "6                             55                              2   \n",
      "7                             55                              3   \n",
      "8                             55                              4   \n",
      "9                             60                              2   \n",
      "10                            60                              3   \n",
      "11                            60                              4   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0   {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
      "1   {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
      "2   {u'model__min_samples_leaf': 40, u'model__min_...               10   \n",
      "3   {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
      "4   {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
      "5   {u'model__min_samples_leaf': 50, u'model__min_...                4   \n",
      "6   {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
      "7   {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
      "8   {u'model__min_samples_leaf': 55, u'model__min_...                1   \n",
      "9   {u'model__min_samples_leaf': 60, u'model__min_...                7   \n",
      "10  {u'model__min_samples_leaf': 60, u'model__min_...                7   \n",
      "11  {u'model__min_samples_leaf': 60, u'model__min_...                7   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.852872            0.890329           0.851990   \n",
      "1            0.852872            0.890329           0.851990   \n",
      "2            0.852872            0.890329           0.851990   \n",
      "3            0.852548            0.885111           0.853779   \n",
      "4            0.852548            0.885111           0.853779   \n",
      "5            0.852548            0.885111           0.853779   \n",
      "6            0.853190            0.882468           0.854142   \n",
      "7            0.853190            0.882468           0.854142   \n",
      "8            0.853190            0.882468           0.854142   \n",
      "9            0.853398            0.880887           0.852516   \n",
      "10           0.853398            0.880887           0.852516   \n",
      "11           0.853398            0.880887           0.852516   \n",
      "\n",
      "    split1_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
      "0             0.886587      2.445979        0.967029        0.000441   \n",
      "1             0.886587      0.710887        0.248440        0.000441   \n",
      "2             0.886587      1.271989        0.064970        0.000441   \n",
      "3             0.881617      1.928839        0.143793        0.000616   \n",
      "4             0.881617      0.491990        0.167560        0.000616   \n",
      "5             0.881617      0.733002        0.027418        0.000616   \n",
      "6             0.879926      0.093329        0.015243        0.000476   \n",
      "7             0.879926      2.498084        0.445194        0.000476   \n",
      "8             0.879926      0.351267        0.364563        0.000476   \n",
      "9             0.877388      0.172686        0.070588        0.000441   \n",
      "10            0.877388      0.390535        0.100172        0.000441   \n",
      "11            0.877388      0.124174        0.147464        0.000441   \n",
      "\n",
      "    std_train_score  \n",
      "0          0.001871  \n",
      "1          0.001871  \n",
      "2          0.001871  \n",
      "3          0.001747  \n",
      "4          0.001747  \n",
      "5          0.001747  \n",
      "6          0.001271  \n",
      "7          0.001271  \n",
      "8          0.001271  \n",
      "9          0.001750  \n",
      "10         0.001750  \n",
      "11         0.001750  \n"
     ]
    }
   ],
   "source": [
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('count_vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_wo...         min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(model__min_samples_leaf=10)\n",
    "pipe.set_params(model__min_samples_split=45)\n",
    "\n",
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score 0.888328756980224\n",
      "Test score 0.851691882419725\n"
     ]
    }
   ],
   "source": [
    "score_test = pipe.score(x_test,y_test)\n",
    "score_train = pipe.score(x_train,y_train)\n",
    "print \"Training score\",score_train\n",
    "print \"Test score\",score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the optimized parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score 0.8650479745781013\n",
      "Test score 0.8563072290643433\n"
     ]
    }
   ],
   "source": [
    "pipe.set_params(model__min_samples_leaf=55)\n",
    "pipe.set_params(model__min_samples_split=2)\n",
    "\n",
    "pipe.fit(x_train,y_train)\n",
    "score_test = pipe.score(x_test,y_test)\n",
    "score_train = pipe.score(x_train,y_train)\n",
    "print \"Training score\",score_train\n",
    "print \"Test score\",score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1 - worst     0.121816162621\n",
      "         2 - horrible  0.0895221393649\n",
      "         3 - told      0.0800539687838\n",
      "         4 - terrible  0.0535061604803\n",
      "         5 - rude      0.0493440619108\n",
      "         6 - delicious 0.0393792571861\n",
      "         7 - amazing   0.030049519427\n",
      "         8 - good      0.0293996003124\n",
      "         9 - bland     0.0293494720182\n",
      "        10 - poor      0.0262188907423\n",
      "        11 - love      0.0238451734639\n",
      "        12 - best      0.0235844653114\n",
      "        13 - asked     0.0223923315486\n",
      "        14 - mediocre  0.0203121218696\n",
      "        15 - friendly  0.0192108859988\n",
      "        16 - minutes   0.016737970685\n",
      "        17 - awesome   0.0157669153367\n",
      "        18 - waste     0.0152809335878\n",
      "        19 - manager   0.0152443166481\n",
      "        20 - disgusting0.014197552684\n",
      "        21 - awful     0.0128177462115\n",
      "        22 - excellent 0.0116831190871\n",
      "        23 - nice      0.0115913956408\n",
      "        24 - wont      0.0113051724844\n",
      "        25 - definitely0.00991120886378\n",
      "        26 - money     0.00935818519086\n",
      "        27 - disappointing0.00784311606643\n",
      "        28 - said      0.00743441410624\n",
      "        29 - sucks     0.00725728290439\n",
      "        30 - overpriced0.00716254194845\n",
      "        31 - bad       0.00678054200681\n",
      "        32 - gross     0.00639963002861\n",
      "        33 - worse     0.00598074714413\n",
      "        34 - disappointed0.00575116308884\n",
      "        35 - dirty     0.00567276084231\n",
      "        36 - little    0.00550458874385\n",
      "        37 - perfect   0.00545516754012\n",
      "        38 - food      0.00472955990015\n",
      "        39 - left      0.00471366494401\n",
      "        40 - ok        0.00445324851867\n",
      "        41 - pretty    0.00440702093555\n",
      "        42 - better    0.00414923968789\n",
      "        43 - wasnt     0.00394098529445\n",
      "        44 - ordered   0.00384514269557\n",
      "        45 - favorite  0.00376466464287\n",
      "        46 - finally   0.00359138153656\n",
      "        47 - service   0.00341384896562\n",
      "        48 - fantastic 0.00338647987574\n",
      "        49 - sorry     0.003343944025\n",
      "        50 - place     0.00332846203679\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1,51):\n",
    "    vocabulary_index = pipe.named_steps['model'].feature_importances_.argsort(axis=0)[-1*idx]\n",
    "    relevance = pipe.named_steps['model'].feature_importances_[vocabulary_index]\n",
    "    word = pipe.named_steps['count_vectorizer'].get_feature_names()[vocabulary_index]\n",
    "    \n",
    "    print(\"{0:10} - {1:10}{2:10}\".format(idx,word,relevance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On a concluding remark, I like this outcome. I see only adjectives which can be described as indicator of experices that one had with something, most probably a bad experience. I wanted my model perform in a way that all the bad reviews to be shown though in the process a few good places will be missed but that's ok. If someone is looking for a place to eat, must not end at a bad place that's the motivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
